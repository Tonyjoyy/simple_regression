{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC11 - Introduction to Machine Learning - A1 - Q2\n",
    "\n",
    "## Image Denoising with RBF Rgression\n",
    "Image Denoising is a long-standing problem in areas of signal processing and computer vision.\n",
    "The measurements in physical processes are typically noisy and noise removal is a crucial step to\n",
    "obtain the underlying ground-truth signal.\n",
    "In this notebook, you are going to use the radial basis regression model that you implemented in the start code, and denoise an input image corrupted by salt-and-pepper noise. You will try different settings of widths of RBFs and their spacings to see their effects. \n",
    "The result of these experiments are visualized using `matplotlib` library.\n",
    "The goal is to describe the plots, characterize overfitting/undefitting scenarios and explain them.\n",
    "\n",
    "**Note:** You don't need to change/write any code in the notebook. After each part, you see the questions that you need to answer. Please provide you answer in the markdown cells and share the noteboook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial imports\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from rbf_regression import RBFRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image\n",
    "First we use `Pillow` library to read the image. To reduce later computations, we resize the image by a factor of two yielding an image of size 384x256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Image\n",
    "image_name = './a1q2.jpg'\n",
    "img = Image.open(image_name)\n",
    "img = img.resize((img.size[0] // 2, img.size[1] // 2))\n",
    "img = np.array(img) / 255 \n",
    "img = img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salt-and-pepper noise\n",
    "\n",
    "Image Denoising is a long-standing problem in areas of signal processing and computer vision.\n",
    "The measurements in physical processes are typically noisy and noise removal is a crucial step to\n",
    "obtain the underlying ground-truth signal. In this question, we aim to deal with the salt-and-pepper\n",
    "noise. \n",
    "With `salt_prob` any pixel changes to white pixel, namely `salt_rgb=(255,255,255)`.\n",
    "With `pepper_prob` any pixel changes to black pixel, namely `salt_rgb=(0,0,0)`.\n",
    "This noise appears as sparsely occurring white and black pixels as shown in the visualization. \n",
    "We simulate this noise for the load image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pepper_rgb = np.array([0, 0, 0])\n",
    "pepper_rgb = pepper_rgb.astype(np.float32) / 255\n",
    "salt_rgb = np.array([255, 255, 255])\n",
    "salt_rgb = salt_rgb.astype(np.float32) / 255\n",
    "\n",
    "def add_salt_and_pepper_noise(image, salt_prob, pepper_prob):\n",
    "    noisy_image = np.copy(image)\n",
    "    \n",
    "    # Add salt noise\n",
    "    salt_pixels = np.random.rand(*image.shape[:-1]) < salt_prob\n",
    "    noisy_image[salt_pixels] = 1\n",
    "\n",
    "    # Add pepper noise\n",
    "    pepper_pixels = np.random.rand(*image.shape[:-1]) < pepper_prob\n",
    "    noisy_image[pepper_pixels] = 0\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "noisy_img = add_salt_and_pepper_noise(img, 0.2, 0.2)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), dpi=200)\n",
    "axs[0].imshow(img)\n",
    "axs[0].set_title('Original Image')\n",
    "axs[1].imshow(noisy_img)\n",
    "axs[1].set_title('Noisy Image')\n",
    "axs[0].set_axis_off()\n",
    "axs[1].set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising function\n",
    "\n",
    "Next, the `denoising` function is defined. This function takes in an image and then split it into individual patches of size `patch_size`. The function iterates through image patches and a separate RBF model is fitted in a regularized fashion (with `l2_coeff` as $lambda$) to each patch. The centers of RBF are placed with even spacing of `spacing` and same widths of `width`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoising(im, spacing, width, patch_size, l2_coeff, tolerance):\n",
    "    im_rec = im.copy() # reconstruction or denoised\n",
    "    H, W = im.shape[:2]\n",
    "\n",
    "    # i corresponds to left-to-right\n",
    "    # j corresponds to up-to-down\n",
    "    for i in range(0, W-patch_size+1, patch_size):\n",
    "        for j in range(0, H-patch_size+1, patch_size):\n",
    "            # Grid of pixel coordinates in the patch\n",
    "            XX, YY = np.meshgrid(np.arange(i, i+patch_size), np.arange(j, j+patch_size))\n",
    "            P = np.stack([YY, XX], axis=0).reshape(-1, 2)\n",
    "            \n",
    "            # Uses squared distance to find indcies to be filled\n",
    "            patch = im[j:j+patch_size, i:i+patch_size]\n",
    "            ref1 = ((patch - salt_rgb) ** 2).sum(axis=2)\n",
    "            ref2 = ((patch - pepper_rgb) ** 2).sum(axis=2)\n",
    "            cond = np.logical_or(ref1 <= tolerance, ref2 <= tolerance)\n",
    "            index_fill = np.argwhere(cond) # if close to fill_rgb, then fill\n",
    "            index_data = np.argwhere(~cond) # if not close to fill_rgb, then data\n",
    "            idx_data = np.sort(index_data[:,1]*ref1.shape[0]+index_data[:,0])\n",
    "            idx_fill = np.sort(index_fill[:,1]*ref1.shape[0]+index_fill[:,0])\n",
    "\n",
    "            # Place RBFs over image patch with even spacing and same widths\n",
    "            XX, YY = np.meshgrid(list(range(i, i+patch_size, spacing)),\n",
    "                                list(range(j, j+patch_size, spacing)))\n",
    "\n",
    "            centers = np.array((XX.flatten(), YY.flatten()), dtype=np.float32).T\n",
    "            num_centers = centers.shape[0]\n",
    "            widths = np.ones(shape=(num_centers, 1), dtype=np.float32) * width\n",
    "\n",
    "            # Construct one model for each color channel\n",
    "            red_model = RBFRegression(centers=centers, widths=widths)\n",
    "            green_model = RBFRegression(centers=centers, widths=widths)\n",
    "            blue_model = RBFRegression(centers=centers, widths=widths)\n",
    "            \n",
    "            # If there are pixels that need to be filled, then we try to train the models and fill.\n",
    "            # Otherwise, we use the original patch\n",
    "            if (idx_fill.size>0):\n",
    "                # print('Reconstructing patch at selected color')\n",
    "                if(idx_data.size <= num_centers):\n",
    "                    # print('Not enough pixels to estimate RBF model! copying patch\\n')\n",
    "                    patch_rec = patch.copy()\n",
    "                else:\n",
    "                    # Valid locations for sampling pixels\n",
    "                    P_data = P[idx_data]\n",
    "\n",
    "                    # Reconstruct each colour layer using a separate RBF model\n",
    "                    # Red channel\n",
    "                    patch_R = patch[:,:,0]\n",
    "                    z_R = patch_R.reshape(patch_R.size, 1, order='F')\n",
    "                    z_R = z_R[idx_data]\n",
    "                    red_model.fit_with_l2_regularization(P_data, z_R, l2_coeff)\n",
    "                    \n",
    "                    # Green channel\n",
    "                    patch_G = patch[:,:,1]\n",
    "                    z_G = patch_G.reshape(patch_G.size, 1, order='F')\n",
    "                    z_G = z_G[idx_data]\n",
    "                    green_model.fit_with_l2_regularization(P_data, z_G, l2_coeff)\n",
    "                    \n",
    "                    # Blue channel\n",
    "                    patch_B = patch[:,:,2]\n",
    "                    z_B = patch_B.reshape(patch_B.size, 1, order='F')\n",
    "                    z_B = z_B[idx_data]\n",
    "                    blue_model.fit_with_l2_regularization(P_data, z_B, l2_coeff)\n",
    "                    \n",
    "                    # Reconstruct pixel values at fill-in locations\n",
    "                    P_fill = P[idx_fill]\n",
    "                    fill_R = red_model.predict(P_fill)\n",
    "                    fill_G = green_model.predict(P_fill)\n",
    "                    fill_B = blue_model.predict(P_fill)\n",
    "                    \n",
    "                    # Assemble reconstructed patch\n",
    "                    patch_rec = patch.copy()\n",
    "                    patch_rec[index_fill[:,0], index_fill[:,1], 0] = np.squeeze(np.asarray(fill_R)) # Red\n",
    "                    patch_rec[index_fill[:,0], index_fill[:,1], 1] = np.squeeze(np.asarray(fill_G)) # Green\n",
    "                    patch_rec[index_fill[:,0], index_fill[:,1], 2] = np.squeeze(np.asarray(fill_B)) # Blue\n",
    "            else:\n",
    "                # print('Copying patch at %d--%d\\n'%(i,j))\n",
    "                patch_rec = patch.copy()\n",
    "            im_rec[j:j+patch_size, i:i+patch_size] = patch_rec\n",
    "    im_rec = np.clip(im_rec, 0, 1)\n",
    "    return im_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising in default setting\n",
    "Using the above function, we run the denoiser in a default setting. The output is visualized and compared with the input and the clean image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_coef = 2\n",
    "tolerance = 0.01\n",
    "spacing = 16 # 1 <= spacing <= 9\n",
    "width = 4 # 1 <= width <= 2 * spacing\n",
    "patch_size = 32 # >=1\n",
    "img_recs = []\n",
    "img_rec = denoising(noisy_img, \n",
    "                    spacing=spacing, width=width, \n",
    "                    patch_size=patch_size, l2_coeff=l2_coef, \n",
    "                    tolerance=tolerance)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 5), dpi=200)\n",
    "axs[0].imshow(img)\n",
    "axs[1].imshow(noisy_img)\n",
    "axs[2].imshow(img_rec)\n",
    "axs[0].set_axis_off()\n",
    "axs[1].set_axis_off()\n",
    "axs[2].set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "Does the denoiser perform well? Do you see any artifacts in the denoised image? What are the potential reasons for these artifacts?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of width\n",
    "\n",
    "Given a certain `spacing=16`, we run denoising with various widths, raning from 1 to `spacing/2`.\n",
    "Then the mean squared error is computed between denoised and clean image. The error is visualized as a function of the width size. \n",
    "Note that running the experiments could take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_coef = 2.5\n",
    "tolerance = 0.01\n",
    "\n",
    "spacing = 16\n",
    "patch_size = 32\n",
    "mses = []\n",
    "widths = np.arange(1, spacing//2).astype(np.int32)\n",
    "for width in widths:\n",
    "    img_rec = denoising(noisy_img, \n",
    "                        spacing=spacing, width=width, \n",
    "                        patch_size=patch_size, l2_coeff=l2_coef, \n",
    "                        tolerance=tolerance)\n",
    "    mse = ((img_rec - img)**2).mean()\n",
    "    mses.append(mse)\n",
    "plt.plot(widths, np.log(1+np.array(mses)))\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('MSE (log scale)')\n",
    "plt.title('Effect of Width on the Denoising Performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "How does the error change when increasing the width? Justify your answer.\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of spacing\n",
    "Given a fixed `width=3`, we run denoising with various spacings, ranging from `width` to `width*4+1`. Here the goal is to explore the effect of the spacing between basis functions. As before, the mean squared error is computed and visualized.\n",
    "Note that running the experiments could take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_coef = 2.0\n",
    "tolerance = 0.01\n",
    "\n",
    "width = 3\n",
    "patch_size = 16\n",
    "mses = []\n",
    "spacings = np.arange(width, width*4+1).astype(np.int32)\n",
    "for spacing in spacings:\n",
    "    img_rec = denoising(noisy_img, \n",
    "                        spacing=spacing, width=width, \n",
    "                        patch_size=patch_size, l2_coeff=l2_coef, \n",
    "                        tolerance=tolerance)\n",
    "    mse = ((img_rec - img)**2).mean()\n",
    "    mses.append(mse)\n",
    "plt.plot(spacings, np.log(1+np.array(mses)))\n",
    "plt.xlabel('Spacing')\n",
    "plt.ylabel('MSE (log scale)')\n",
    "plt.title('Effect of Spacing on the Denoising Performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "Discuss how the error changes when increasing the spacing. Justifications are required.\n",
    "\n",
    "**Answer:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
